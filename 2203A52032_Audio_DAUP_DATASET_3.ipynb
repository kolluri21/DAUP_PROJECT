{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2kERdygizIj",
        "outputId": "010c2f87-802f-4e90-e688-f56ff4550153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "WKko3BRSqT9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_PATH = \"/content/drive/MyDrive/Birds\"\n",
        "\n",
        "MAX_LEN = 40\n",
        "SAMPLE_RATE = 22050\n",
        "N_MFCC = 13\n",
        "\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC).T\n",
        "\n",
        "    if mfcc.shape[0] < MAX_LEN:\n",
        "        pad_width = MAX_LEN - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:MAX_LEN]\n",
        "    return mfcc\n"
      ],
      "metadata": {
        "id": "kqaGEjMhDnZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = [], []\n",
        "\n",
        "# Loop through folders and extract features\n",
        "for label in os.listdir(AUDIO_PATH):\n",
        "    folder = os.path.join(AUDIO_PATH, label)\n",
        "    if os.path.isdir(folder):\n",
        "        for file in os.listdir(folder):\n",
        "            if file.endswith('.wav'):\n",
        "                file_path = os.path.join(folder, file)\n",
        "                try:\n",
        "                    mfcc = extract_features(file_path)\n",
        "                    X.append(mfcc)\n",
        "                    y.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode class labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y_encoded = tf.keras.utils.to_categorical(y_encoded)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data loaded. Shape: {X.shape}, Labels: {le.classes_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jqOOQq0dDuOX",
        "outputId": "6a4a8b04-1517-469e-d5d1-99bccb446943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Birds'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-48d531b03850>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loop through folders and extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Birds'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the audio file\n",
        "audio_file_path = \"/content/drive/MyDrive/Birds/Bird Sound/101308-0.wav\"\n",
        "y, sr = librosa.load(audio_file_path)\n",
        "\n",
        "# Plot the audio waveform\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "plt.title(\"Audio Waveform\")\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dwfnXsu4EIBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "audio_file_path = \"/content/drive/MyDrive/Birds/Bird Sound/101308-0.wav\"\n",
        "y, sr = librosa.load(audio_file_path)\n",
        "\n",
        "# Extract MFCCs\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "# Plot the MFCCs\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('MFCCs')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7_Nl2pcVEPO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(MAX_LEN, N_MFCC)),\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(y_encoded.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "wIWnNQ5cEUta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vb-YdGC6EzOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "        mfccs = mfccs.T\n",
        "        mfccs = mfccs[:40]\n",
        "        if mfccs.shape[0] < 40:\n",
        "            pad_width = 40 - mfccs.shape[0]\n",
        "            mfccs = np.pad(mfccs, ((0, pad_width), (0, 0)), mode='constant')\n",
        "        return mfccs\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting features from {file_path}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "X2ZJlyfGE2QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa\n",
        "!pip install resampy"
      ],
      "metadata": {
        "id": "39bCI-G4E436"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "JXGh7ZBGE7Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder = r\"/content/drive/MyDrive/Birds\"\n",
        "print(os.listdir(folder))"
      ],
      "metadata": {
        "id": "-sUwL4yYE-ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=le.classes_)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "orh7ANCsFIxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RpDGNGtjFNFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa resampy numpy"
      ],
      "metadata": {
        "id": "gKDbGfeAFRRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa resampy numpy scikit-learn"
      ],
      "metadata": {
        "id": "RXb9Ex2RFU8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "import os"
      ],
      "metadata": {
        "id": "5dG3fazTFXue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_path):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, sr=22050, duration=4.0)\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "        if mfccs.shape[1] < 40:\n",
        "            pad_width = 40 - mfccs.shape[1]\n",
        "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :40]\n",
        "        return mfccs.T\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting features from {file_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ojSKcrcIFazY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Prediction function\n",
        "def predict_gender(audio_file_path):\n",
        "    mfccs = extract_features(audio_file_path)\n",
        "    if mfccs is not None:\n",
        "        mfccs = np.expand_dims(mfccs, axis=0)  # Shape: (1, 40, 13)\n",
        "        prediction = model.predict(mfccs)\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        predicted_label = le.inverse_transform([predicted_class])[0]\n",
        "        return predicted_label\n",
        "    else:\n",
        "        return \"Error extracting features.\""
      ],
      "metadata": {
        "id": "-4m2JzMBFdF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    audio_file_path = fn\n",
        "    predicted_gender = predict_gender(audio_file_path)\n",
        "    print(f\"Predicted gender for {audio_file_path}: {predicted_gender}\")\n",
        "\n",
        "    mfccs = extract_features(audio_file_path)\n",
        "\n",
        "    if mfccs is not None:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(mfccs.T, sr=SAMPLE_RATE, x_axis='time')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title(f'MFCCs for {audio_file_path} (Predicted: {predicted_gender})')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "ipd.Audio(audio_file_path)\n"
      ],
      "metadata": {
        "id": "veHL19yPFfWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    audio_file_path = fn\n",
        "    predicted_gender = predict_gender(audio_file_path)\n",
        "    print(f\"Predicted gender for {audio_file_path}: {predicted_gender}\")\n",
        "\n",
        "    mfccs = extract_features(audio_file_path)\n",
        "\n",
        "    if mfccs is not None:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(mfccs.T, sr=SAMPLE_RATE, x_axis='time')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title(f'MFCCs for {audio_file_path} (Predicted: {predicted_gender})')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "ipd.Audio(audio_file_path)\n"
      ],
      "metadata": {
        "id": "5dzarP1ZFukL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}